{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a5c110a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "badaea9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model and the scaler\n",
    "model = load_model(\"trained_model.h5\")\n",
    "scaler_filename = \"scaler.save\"\n",
    "scaler = joblib.load(scaler_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b05188b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_func(data):\n",
    "    # Preprocess the data\n",
    "    new_data = data.interpolate(method='cubic', limit_direction='both')\n",
    "    new_data = new_data.filter(['Close'])\n",
    "    scaled_data = scaler.transform(new_data.values.reshape(-1, 1))\n",
    "\n",
    "    # Prepare the input for prediction\n",
    "    x_test = np.reshape(scaled_data, (1, scaled_data.shape[0], 1))\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(x_test)\n",
    "    \n",
    "    # Inverse transform the predictions\n",
    "    predicted_data = scaler.inverse_transform(predictions)\n",
    "\n",
    "    return predicted_data.flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c2f6562",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pd.read_csv('sample_input.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e2622620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000018658062790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 653ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7218.70654296875, 7245.041015625]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_func(pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bad6ee0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    # Input the csv file\n",
    "    \"\"\"\n",
    "    Sample evaluation function\n",
    "    Don't modify this function\n",
    "    \"\"\"\n",
    "    df = pd.read_csv('sample_input.csv')\n",
    "     \n",
    "    actual_close = np.loadtxt('sample_close.txt')\n",
    "    \n",
    "    pred_close = predict_func(df)\n",
    "    \n",
    "    # Calculation of squared_error\n",
    "    actual_close = np.array(actual_close)\n",
    "    pred_close = np.array(pred_close)\n",
    "    mean_square_error = np.mean(np.square(actual_close-pred_close))\n",
    "\n",
    "\n",
    "    pred_prev = [df['Close'].iloc[-1]]\n",
    "    pred_prev.append(pred_close[0])\n",
    "    pred_curr = pred_close\n",
    "    \n",
    "    actual_prev = [df['Close'].iloc[-1]]\n",
    "    actual_prev.append(actual_close[0])\n",
    "    actual_curr = actual_close\n",
    "\n",
    "    # Calculation of directional_accuracy\n",
    "    pred_dir = np.array(pred_curr)-np.array(pred_prev)\n",
    "    actual_dir = np.array(actual_curr)-np.array(actual_prev)\n",
    "    dir_accuracy = np.mean((pred_dir*actual_dir)>0)*100\n",
    "\n",
    "    print(f'Mean Square Error: {mean_square_error:.6f}\\nDirectional Accuracy: {dir_accuracy:.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6d808da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n",
      "Mean Square Error: 630.892529\n",
      "Directional Accuracy: 100.0\n"
     ]
    }
   ],
   "source": [
    "if __name__== \"__main__\":\n",
    "    evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61657c19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b35074",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
